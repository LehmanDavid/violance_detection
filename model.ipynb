{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: weights: File exists\n",
      "/Users/david/Desktop/violance_detection/venv/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/david/Desktop/violance_detection/venv/lib/python3.9/site-packages/gdown/cli.py:132: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1rlZ-xTkTMjgWKiQFUedRnHlDgQwx6yTm\n",
      "From (redirected): https://drive.google.com/uc?id=1rlZ-xTkTMjgWKiQFUedRnHlDgQwx6yTm&confirm=t&uuid=aa733e44-07e7-4b3b-be72-ea5fe1f80cc2\n",
      "To: /Users/david/Desktop/violance_detection/weights/weights.h5\n",
      "100%|████████████████████████████████████████| 320M/320M [00:49<00:00, 6.41MB/s]\n"
     ]
    }
   ],
   "source": [
    "# downloads C3D weights from https://github.com/aslucki/C3D_Sport1M_keras\n",
    "!mkdir weights\n",
    "!gdown --id 1rlZ-xTkTMjgWKiQFUedRnHlDgQwx6yTm -O weights/weights.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# C3D definition\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv3D, MaxPooling3D, ZeroPadding3D\n",
    "\n",
    "def create_C3D_model(summary = False):\n",
    "    \"\"\"Creates model object with the sequential API: https://keras.io/models/sequential/\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    summary : bool\n",
    "              if True, prints the model summary (default False)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : Sequential\n",
    "            The instantiated model\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    input_shape = (16, 112, 112, 3)\n",
    "\n",
    "    model.add(Conv3D(64, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv1',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2),\n",
    "                           padding='valid', name='pool1'))\n",
    "    # 2nd layer group\n",
    "    model.add(Conv3D(128, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv2'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool2'))\n",
    "    # 3rd layer group\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv3a'))\n",
    "    model.add(Conv3D(256, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv3b'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool3'))\n",
    "    # 4th layer group\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv4a'))\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv4b'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool4'))\n",
    "    # 5th layer group\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv5a'))\n",
    "    model.add(Conv3D(512, (3, 3, 3), activation='relu',\n",
    "                     padding='same', name='conv5b'))\n",
    "    model.add(ZeroPadding3D(padding=((0, 0), (0, 1), (0, 1)), name='zeropad5'))\n",
    "    model.add(MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2),\n",
    "                           padding='valid', name='pool5'))\n",
    "    model.add(Flatten())\n",
    "    # FC layers group\n",
    "    model.add(Dense(4096, activation='relu', name='fc6'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(4096, activation='relu', name='fc7'))\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(Dense(487, activation='softmax', name='fc8'))\n",
    "\n",
    "    if summary:\n",
    "      print(model.summary())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for the experiments (chunk count, video preprocessing, feature computation, )\n",
    "from keras.models import Model\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def getFeatureExtractor(weigthsPath, layer, verbose = False):\n",
    "    \"\"\"Gets the C3D feature extractor\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    weightsPath : str\n",
    "                  Pathname of the weights file for the C3D model.\n",
    "    layer : str\n",
    "            Name of the output layer for the feature extractor\n",
    "    verbose : bool\n",
    "              if True print debug logs (default True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    Model : Model class\n",
    "            Feature extractor\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    model = create_C3D_model(verbose)\n",
    "    model.load_weights(weigthsPath)\n",
    "    model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "    return Model(inputs=model.input,outputs=model.get_layer(layer).output)\n",
    "\n",
    "def count_chunks(videoBasePath):\n",
    "    \"\"\"Counts the 16 frames lenght chunks available in a dataset organized in violent and non-violent,\n",
    "    cam1 and cam2 folders, placed at videoBasePath.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    videoBasePath : str\n",
    "                    Base path of the dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cnt : int\n",
    "          number of 16 frames lenght chunks in the dataset\n",
    "    \"\"\"\n",
    "\n",
    "    folders = ['violent', 'non-violent']\n",
    "    cams = ['cam1', 'cam2']\n",
    "    cnt = 0\n",
    "\n",
    "    for folder in folders:\n",
    "        for camName in cams:\n",
    "            path = os.path.join(videoBasePath, folder, camName)\n",
    "\n",
    "            videofiles = os.listdir(path)\n",
    "            for videofile in videofiles:\n",
    "                filePath = os.path.join(path, videofile)\n",
    "                video = cv2.VideoCapture(filePath)\n",
    "                numframes = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "                chunks = numframes//16\n",
    "                cnt += chunks\n",
    "\n",
    "\n",
    "    return cnt\n",
    "\n",
    "def preprocessVideos(videoBasePath, featureBasePath, verbose=True):\n",
    "    \"\"\"Preproccess all the videos.\n",
    "\n",
    "    It extracts samples for the input of C3D from a video dataset, organised in violent and non-violent, cam1 and cam2 folders.\n",
    "    The samples and the labels are store on two memmap numpy arrays, called samples.mmap and labels.mmap, at \"featureBasePath\".\n",
    "    The numpy array with samples has shape (Chunk #, 16, 112, 112, 3), the labels array has shape (Chunk # 16, 112, 112, 3).\n",
    "    For the AIRTLab dataset the number of chunks is 3537.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    videoBasePath : str\n",
    "                    Pathname to the base of the video repository, which contains two directories,\n",
    "                    violent and non-violent, which are divided into cam1 and cam2.\n",
    "    featureBasePath : str\n",
    "                      it is the pathname of a base where the numpy arrays have to be saved.\n",
    "    verbose : bool\n",
    "              if True print debug logs (default True)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    folders = ['violent', 'non-violent']\n",
    "    cams = ['cam1', 'cam2']\n",
    "    total_chunks = count_chunks(videoBasePath)\n",
    "    npSamples = np.memmap(os.path.join(featureBasePath, 'samples.mmap'), dtype=np.float32, mode='w+', shape=(total_chunks, 16, 112, 112, 3))\n",
    "    npLabels = np.memmap(os.path.join(featureBasePath, 'labels.mmap'), dtype=np.int8, mode='w+', shape=(total_chunks))\n",
    "    cnt = 0\n",
    "\n",
    "    for folder in folders:\n",
    "        for camName in cams:\n",
    "            path = os.path.join(videoBasePath, folder, camName)\n",
    "\n",
    "            videofiles = os.listdir(path)\n",
    "            for videofile in videofiles:\n",
    "                filePath = os.path.join(path, videofile)\n",
    "                video = cv2.VideoCapture(filePath)\n",
    "                numframes = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "                chunks = numframes//16\n",
    "                if verbose:\n",
    "                    print(filePath)\n",
    "                    print(\"*** [Video Info] Number of frames: {} - fps: {} - chunks: {}\".format(numframes, fps, chunks))\n",
    "                vid = []\n",
    "                videoFrames = []\n",
    "                while True:\n",
    "                    ret, img = video.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    videoFrames.append(cv2.resize(img, (112, 112)))\n",
    "                vid = np.array(videoFrames, dtype=np.float32)\n",
    "                filename = os.path.splitext(videofile)[0]\n",
    "                chunk_cnt = 0\n",
    "                for i in range(chunks):\n",
    "                    X = vid[i*16:i*16+16]\n",
    "                    chunk_cnt += 1\n",
    "                    npSamples[cnt] = np.array(X, dtype=np.float32)\n",
    "                    if folder == 'violent':\n",
    "                        npLabels[cnt] = np.int8(1)\n",
    "                    else:\n",
    "                        npLabels[cnt] = np.int8(0)\n",
    "                    cnt += 1\n",
    "\n",
    "    if verbose:\n",
    "        print(\"** Labels **\")\n",
    "        print(npLabels.shape)\n",
    "        print('\\n****\\n')\n",
    "        print(\"** Samples **\")\n",
    "        print(npSamples.shape)\n",
    "        print('\\n****\\n')\n",
    "\n",
    "    del npSamples\n",
    "    del npLabels\n",
    "\n",
    "def extractFeatures(weigthsPath, videoBasePath, featureBasePath='', verbose=True):\n",
    "    \"\"\"Extracts features from a video dataset, using fc6 of the C3D network.\n",
    "\n",
    "    It extracts features from a video dataset, organized in violent and non-violent, cam1 and cam2 folders.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    weightsPath : str\n",
    "                  Pathname of the weights file for the C3D model.\n",
    "    videoBasePath : str\n",
    "                    Pathname to the base of the video repository, which contains two directories,\n",
    "                    violent and non-violent, which are divided into cam1 and cam2.\n",
    "    featureBasePath : str\n",
    "                      if non-empty, it is the pathname of a base where numpy array has to be saved.\n",
    "                      It assumes it is organized in violent, non-violent, cam1 and cam2 exactly as\n",
    "                      the video repository (default '').\n",
    "    verbose : bool\n",
    "              if True print debug logs (default True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy.ndarray\n",
    "        Features array of shape (Num of video chunks, 4096) representing the 4096-dim feature vector for each video\n",
    "        chunk in the dataset\n",
    "    y : numpy.ndarray\n",
    "        Labels array of shape (Num of video chunks) representing the labels for all the video chunks in the dataset\n",
    "        (1 = violent, 2 = non violent)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    featureExtractor = getFeatureExtractor(weigthsPath, 'fc6', verbose)\n",
    "\n",
    "    folders = ['violent', 'non-violent']\n",
    "    cams = ['cam1', 'cam2']\n",
    "    labels = []\n",
    "    features = []\n",
    "\n",
    "    for folder in folders:\n",
    "        for camName in cams:\n",
    "            path = os.path.join(videoBasePath, folder, camName)\n",
    "            featurepath = os.path.join(featureBasePath, folder, camName)\n",
    "\n",
    "            videofiles = os.listdir(path)\n",
    "            for videofile in videofiles:\n",
    "                filePath = os.path.join(path, videofile)\n",
    "                video = cv2.VideoCapture(filePath)\n",
    "                numframes = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "                fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "                chunks = numframes//16\n",
    "                if verbose:\n",
    "                    print(filePath)\n",
    "                    print(\"*** [Video Info] Number of frames: {} - fps: {} - chunks: {}\".format(numframes, fps, chunks))\n",
    "                vid = []\n",
    "                videoFrames = []\n",
    "                while True:\n",
    "                    ret, img = video.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    videoFrames.append(cv2.resize(img, (112, 112)))\n",
    "                vid = np.array(videoFrames, dtype=np.float32)\n",
    "\n",
    "                filename = os.path.splitext(videofile)[0]\n",
    "                if featureBasePath:\n",
    "                    featureFilePath = os.path.join(featurepath, filename + '.csv')\n",
    "                    with open(featureFilePath, 'ab') as f:\n",
    "                        for i in range(chunks):\n",
    "                            X = vid[i*16:i*16+16]\n",
    "                            out = featureExtractor.predict(np.array([X]))\n",
    "                            np.savetxt(f, out)\n",
    "                            out = out.reshape(4096)\n",
    "                            features.append(out)\n",
    "                            if folder == 'violent':\n",
    "                                labels.append(1)\n",
    "                            else:\n",
    "                                labels.append(0)\n",
    "\n",
    "                    if verbose:\n",
    "                        print('*** Saved file: ' + featureFilePath)\n",
    "                        print('\\n')\n",
    "                else:\n",
    "                    for i in range(chunks):\n",
    "                        X = vid[i*16:i*16+16]\n",
    "                        out = featureExtractor.predict(np.array([X]))\n",
    "                        out = out.reshape(4096)\n",
    "                        features.append(out)\n",
    "                        if folder == 'violent':\n",
    "                            labels.append(1)\n",
    "                        else:\n",
    "                            labels.append(0)\n",
    "\n",
    "    y = np.array(labels)\n",
    "    X = np.array(features)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"** Labels **\")\n",
    "        # print(y)\n",
    "        print(y.shape)\n",
    "        print('\\n****\\n')\n",
    "        print(\"** Features **\")\n",
    "        # print(X)\n",
    "        print(X.shape)\n",
    "        print('\\n****\\n')\n",
    "\n",
    "    return X, y\n",
    "\n",
    "def get_labels_and_features_from_files(basePath, verbose=True):\n",
    "    \"\"\"\"Generates the feature array and the labels from saved feature files.\n",
    "\n",
    "    It generates features and labels from saved features files, organised in violent and\n",
    "    non-violent, cam1 and cam2 folders.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    basePath : str\n",
    "               Pathname to the base of the feature files repository, which contains two directories,\n",
    "               violent and non-violent, which are divided into cam1 and cam2.\n",
    "    verbose : bool\n",
    "              if True print debug logs (default True)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : numpy.ndarray\n",
    "        Features array of shape (Num of video chunks, 4096) representing the 4096-dim feature vector for each video\n",
    "        chunk in the dataset\n",
    "    y : numpy.ndarray\n",
    "        Labels array of shape (Num of video chunks) representing the labels for all the video chunks in the dataset\n",
    "        (1 = violent, 2 = non violent)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    folders = ['violent', 'non-violent']\n",
    "    cams = ['cam1', 'cam2']\n",
    "    labels = []\n",
    "    features = []\n",
    "\n",
    "    for folder in folders:\n",
    "        for camName in cams:\n",
    "            path = os.path.join(basePath, folder, camName)\n",
    "\n",
    "            textfiles = os.listdir(path)\n",
    "            for textfile in textfiles:\n",
    "                filePath = os.path.join(path, textfile)\n",
    "                chunks = np.loadtxt(filePath)\n",
    "                for chunk in chunks:\n",
    "                  features.append(chunk)\n",
    "                  if folder == 'violent':\n",
    "                    labels.append(1)\n",
    "                  else:\n",
    "                    labels.append(0)\n",
    "\n",
    "    y = np.array(labels)\n",
    "    X = np.array(features)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"** Labels **\")\n",
    "        # print(y)\n",
    "        print(y.shape)\n",
    "        print('\\n****\\n')\n",
    "        print(\"** Features **\")\n",
    "        # print(X)\n",
    "        print(X.shape)\n",
    "        print('\\n****\\n')\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction with C3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folders to store samples and features during the experiments\n",
    "\n",
    "!rm -rf airtlabDataset\n",
    "!mkdir airtlabDataset\n",
    "!mkdir airtlabDataset/violent\n",
    "!mkdir airtlabDataset/violent/cam1\n",
    "!mkdir airtlabDataset/violent/cam2\n",
    "!mkdir airtlabDataset/non-violent\n",
    "!mkdir airtlabDataset/non-violent/cam1\n",
    "!mkdir airtlabDataset/non-violent/cam2\n",
    "!mkdir airtlabDataset/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractFeatures('weights/weights.h5', 'datarepo/violence-detection-dataset', 'airtlabDataset', True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing C3D + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1: C3D + SVM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, confusion_matrix, classification_report\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "X, y = get_labels_and_features_from_files('airtlabDataset', False)\n",
    "\n",
    "\n",
    "# Cross Validation\n",
    "clf = svm.SVC(kernel='linear', C = 1, probability=True)\n",
    "\n",
    "nsplits = 5\n",
    "cv = StratifiedShuffleSplit(n_splits=nsplits, train_size=0.8, random_state=42)\n",
    "\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "scores = []\n",
    "sens = np.zeros(shape=(nsplits))\n",
    "specs = np.zeros(shape=(nsplits))\n",
    "f1Scores = np.zeros(shape=(nsplits))\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "plt.figure(num=1, figsize=(10,10))\n",
    "i = 1\n",
    "for train, test in cv.split(X, y):\n",
    "    # train = sklearn.utils.shuffle(train)\n",
    "    clf.fit(X[train], y[train])\n",
    "    pred_acc = clf.predict(X[test])\n",
    "    split_acc = accuracy_score(y[test], pred_acc)\n",
    "    scores.append(split_acc)\n",
    "    prediction = clf.predict_proba(X[test])\n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], prediction[:, 1], pos_label=1)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC split %d (AUC = %0.4f)' % (i, roc_auc))\n",
    "    print('confusion matrix split ' + str(i))\n",
    "    print(confusion_matrix(y[test], pred_acc))\n",
    "\n",
    "    report = classification_report(y[test], pred_acc, target_names=['non-violent', 'violent'], output_dict=True)\n",
    "    sens[i - 1] = report['violent']['recall']\n",
    "    specs[i - 1] = report['non-violent']['recall']\n",
    "    f1Scores[i - 1] = report['violent']['f1-score']\n",
    "    print(classification_report(y[test], prediction.argmax(axis=-1), target_names=['non-violent', 'violent']))\n",
    "    print('Accuracy: ' + str(split_acc))\n",
    "    print('\\n')\n",
    "    i += 1\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r', label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b', label=r'Mean ROC (AUC = %0.4f %0.4f)' % (mean_auc, std_auc), lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2, label=r'1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.01, 1.01])\n",
    "plt.ylim([-0.01, 1.01])\n",
    "plt.xlabel('False Positive Rate',fontsize=18)\n",
    "plt.ylabel('True Positive Rate',fontsize=18)\n",
    "plt.title('Cross-Validation ROC of C3D + SVM model',fontsize=18)\n",
    "plt.legend(loc=\"lower right\", prop={'size': 15})\n",
    "\n",
    "plt.savefig('C3D_SVM' + '.pdf')\n",
    "plt.show()\n",
    "\n",
    "print('Accuracies')\n",
    "print(scores)\n",
    "print('Sensitivities')\n",
    "print(sens)\n",
    "print('specificities')\n",
    "print(specs)\n",
    "print('F1-scores')\n",
    "print(f1Scores)\n",
    "print(\"Avg accuracy: {0} +/- {1}\".format(np.mean(scores, axis=0), np.std(scores, axis=0)))\n",
    "print(\"Avg sensitivity: {0} +/- {1}\".format(np.mean(sens), np.std(sens)))\n",
    "print(\"Avg specificity: {0} +/- {1}\".format(np.mean(specs), np.std(specs)))\n",
    "print(\"Avg f1-score: {0} +/- {1}\".format(np.mean(f1Scores), np.std(f1Scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
